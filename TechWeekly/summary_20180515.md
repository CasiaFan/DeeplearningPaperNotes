## 1. Network Architecture 

### 1). Differentiable Plasticity: training plastic neural network with back-propagation 

([Paper](https://arxiv.org/pdf/1804.02464.pdf)) ([Code](https://github.com/uber-common/differentiable-plasticity))

**核心思想：** **plastic connection** following **Hebb' rule**: 如果一个神经元反复用来激活另一个，那么这两个之间的连接就会被增强。基于这个原理（在遗传算法中很常用）在深度学习中探索了一种可以通过BP学习的plastic connection.

![image1-1](pic/image_015.jpg)

通过控制$a_i,_j$和$w_i,_j$的值就可以控制连接是固定的还是plastic的，这两个参数是网络的结构参数，能继承到不同的episode中，通过梯度下降进行学习；而$Hebb_i,_j$在每个episode都初始化为0，并且完全只是在当前episode中发挥作用；学习率在$\eta$在所有网络和episode中都是相同的。

但是在Equation 2中，weight decay $\eta$避免了Hebb trace的runaway positive feedback，但是如果长期缺少输入没有激活的话就是衰减到0，因此可以采用[Oja rule](http://www.scholarpedia.org/article/Oja_learning_rule)来避免：

$Hebb_i,_j(t+1)=Hebb_i,_j(t)+\eta x_j(t)(x_i(t-1)-x_j(t)Hebb_j,_j(t))$ 

**实验结果:**

1. Pattern memorization: Binary patterns

   Task: quickly memorizing sets of arbitrary high-dimensional patterns (including novel patterns never seen during training), and reconstructing these patterns when exposed to partial, degraded versions of them.

   ![image1-2](pic/image_016.jpg)

   ![image1-3](pic/image_017.jpg)

   记忆大图片的效果：

   ![image1-4](pic/image_018.jpg)

   每个连接使用独立的plasticity coefficient 可以提高网络的表现能力。

   ![image1-5](pic/image_021.jpg)

2. One-shot pattern classification: Omniglot test 

   1623种手写体，每类20个样本

   ![image1-6](pic/image_019.jpg)

3. Reinforcement Learning: Maze exploration task

   ![image1-7](pic/image_020.jpg)

### 2). Self-Attention Generative Adversarial Networks (SAGAN)

([Paper](https://www.arxiv-vanity.com/papers/1805.08318/)) 

**核心技术： ** 将**[Self-Attention](https://arxiv.org/pdf/1706.03762.pdf)**机制引入GAN. 1). use cues from **all feature location** instead of only spatially local points.; 2). discriminator可以check图片中距离较远的不同区域的highly-detailed feature之间是否互相一致。3). generator conditioning会影响GAN的表现，这里使用了[spectral normalization](https://arxiv.org/abs/1802.05957)来提高训练的dynamics;以及使用了Imbalanced learning rate for generator and discriminator updates.

**Self-Attention mechanism:** 

![image1-2-1](pic/image_022.jpg)

![image1-2-2](pic/image_023.jpg)

![image1-2-3](pic/image_024.jpg)

![image1-2-4](pic/image_027.jpg)

**实验结果:**

![image1-2-5](pic/image_025.jpg)

![image1-2-6](pic/image_026.jpg)




## 2. Model Compression

### 1). Google Learn2Compress service in ML Kit

([Blog](https://ai.googleblog.com/2018/05/custom-on-device-ml-models.html)) ([Apply Link](https://docs.google.com/forms/d/e/1FAIpQLSd7Uzx6eepXeF5osByifFsBT_L3BJOymIEjG9uz1wa51Fl9dA/formResponse))

**核心技术**： Learn2Compress主要包含**模型剪枝，量化，联合训练和知识蒸馏**方法，支持将**TF Lite**的模型进行内存优化和加速。

![image2-1](pic/image_022.png)

- 剪枝： 能过压缩2x的模型尺寸，并且保留97%的精度

- 量化：8-bit fixed point 量化

- 联合训练和知识蒸馏： teacher-student learning strategy： 用大的teacher网络训练一个紧凑的student网络并减少精度损失。Teacher网络可以被固定（distillation的时候）或者进行联合优化，而且一般会同时训练多个不同大小和inference效率的student网络提供选择。

  ![image2-2](pic/image_023.png)

目前该技术支持的模型包括**MobileNet， NASNet， inception，[ProjectionNet](https://arxiv.org/pdf/1708.00630.pdf)**的**分类**任务；由于功能仍然在测试阶段，因此需要申请。

**实验结果：**

**推测精度：**

![image2-3](pic/image_024.png)

**推测速度**：

![image2-4](pic/image_025.png)




## 3. Face Recognition

### 1). Pose-Robust Face Recognition via Deep Residual Equivariant Mapping

([Paper](https://arxiv.org/abs/1803.00839)) ([Code](https://github.com/penincillin/DREAM))

**核心技术**：DREAM模块（深度残差等变映射）：首先假设在深度**特征空间**中，侧脸区域的特征和正脸区域的特征相关，即输入任意姿势的图像，可以通过添加残差映射函数将特征映射到正脸的特征空间上（特征等变性理论）。

![image3-1](http://5b0988e595225.cdn.sohucs.com/images/20180313/98cd6481724d4668a7188fd30ced19bf.jpeg)

DREAM模块：引入soft-gate控制机制来自适应控制残差量从而可以控制不同人脸姿势的中引入的残差量（正脸引入少而极侧脸引入较多）；此模块可以直接加入到现有的网络框架中，与主干CNN进行联合端到端的训练。

![image3-2](http://5b0988e595225.cdn.sohucs.com/images/20180313/1895fc8e8b62445c961f464cced6bfb2.jpeg)

**优势**：

1. 实施简单，DREAM模块可以直接拼接到现有的模型，无需改变现有的脸部特征的维度，并且可以直接BP端到端的训练
2. 轻量，添加的参数很少，不会对模型性能造成较大的影响（ResNet18中参数量只增加0.3%，时间成本增加1.6%）。而之前常用的正脸化方法包括**3D人脸归一化**到正脸，**GAN**网络生成正脸的方法开销比较大，而且极侧脸的转化还是很困难。
3. 在不影响正脸识别效果的基础上提高极侧脸的识别率。不需要更详细的人脸数据。

**讨论：**本文认为目前的人脸识别技术在侧脸表现差的原因主要在于训练的时候**正侧脸数据不均衡**导致的。

**实验结果**：

侧脸转换成正脸的效果：

![image3-3](http://5b0988e595225.cdn.sohucs.com/images/20180313/2ae94b78504e45bfaf2312870d47a9bc.jpeg)

错误率：

![image3-4](http://5b0988e595225.cdn.sohucs.com/images/20180313/4af247108bd846a481ed6fb1ed624cab.jpeg)

对侧脸假阳性和假阴性样本的效果：

![image3-5](http://5b0988e595225.cdn.sohucs.com/images/20180313/fa311b3b79164e3d8b5d55856f2c72a2.jpeg)

